# -*- coding: utf-8 -*-
"""Copy of HW2 template

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e-kxUTydxt1Qp-Zk1GWsdV_7yDmq-tYb

#HW1 - Data Exploration and Preparation
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from matplotlib import pylab
params = {'xtick.labelsize': 18,
 'ytick.labelsize': 18,
 'axes.titlesize' : 22,
 'axes.labelsize' : 20,
 'legend.fontsize': 18,
 'legend.title_fontsize': 22,
 'figure.titlesize': 24
 }
pylab.rcParams.update(params)

#Preliminary: Data Loading
df = pd.read_csv(r'virus_data.csv')

from sklearn.model_selection import train_test_split
train , test = train_test_split(df, test_size = 0.2, random_state = (73 + 98)) 

from prepare_HW2 import prepare_data

# write our dataframe to the files
# Prepare training set according to itself
train_df_prepared = prepare_data(train, train)
# Prepare test set according to the raw training set
test_df_prepared = prepare_data(train, test)
# save to csv files
train_df_prepared.to_csv("train.csv", index=False)
test_df_prepared.to_csv("test.csv", index=False)

#Q1
train = pd.read_csv(r'train.csv')
test = pd.read_csv(r'test.csv')
train_pcr1_2 = train[["PCR_01", "PCR_02", "spread"]]
sns.jointplot(train_pcr1_2.PCR_01, train_pcr1_2.PCR_02, hue=train_pcr1_2.spread, palette='pastel')
plt.subplots_adjust(top=0.9)
## TODO: GRID!
plt.suptitle(t="Q1 TITLE")

def visualize_clf(clf, X, Y, title, 
                  xlabel, ylabel,
                  marker_size=50,
                  grid_length=300,
                  linewidths=None):
    import matplotlib.pyplot as plt
    import pandas as pd
    from matplotlib.colors import ListedColormap
    
    if isinstance(X, pd.DataFrame):
        X = X.to_numpy()
        
    # For internal use here, make sure labels are 0 and 1
    Y = np.ravel(Y).astype(int)
    labels = set(Y)
    assert len(labels) == 2, "Can only visualize two unique labels"

    if labels == set([-1,1]):
      Y = (Y + 1) // 2
      labels = set(Y)
    
    assert labels == set([0,1]), "Could not handle given labels"

    plt.figure(figsize=(8, 8))

    # Parameters
    n_classes = 2
    markers = ["D", "o"]
    palette = sns.color_palette("hls", 2)
    custom_cmap = ListedColormap(palette.as_hex())

    x_delta = np.abs(X[:, 0].max() - X[:, 0].min()) * 0.1
    y_delta = np.abs(X[:, 1].max() - X[:, 1].min()) * 0.1
    x_min, x_max = X[:, 0].min() - x_delta, X[:, 0].max() + x_delta
    y_min, y_max = X[:, 1].min() - y_delta, X[:, 1].max() + y_delta
    xx, yy = np.meshgrid(np.linspace(x_min, x_max, grid_length),
                         np.linspace(y_min, y_max, grid_length))
    plt.tight_layout(h_pad=0.5, w_pad=0.5, pad=2.5)

    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])
    Z = Z.reshape(xx.shape)

    cs = plt.contourf(xx, yy, Z, cmap=custom_cmap, alpha=0.35)

    plt.xlabel(xlabel)
    plt.ylabel(ylabel)
    plt.grid(alpha=0.75)

    # Plot the training points
    for i, color, marker in zip(labels, palette, markers):
        idx = np.where(Y == i)
        plt.scatter(X[idx, 0], X[idx, 1], color=color,
                    marker=marker,
                    edgecolor='white', s=marker_size,
                    linewidths=linewidths)

    plt.title(title, fontsize=20)
    plt.axis("tight")
    plt.show()

#Q2
from sklearn.neighbors import KNeighborsClassifier
X_train = train_pcr1_2[["PCR_01", "PCR_02"]]
y_train = train_pcr1_2["spread"]
knn = KNeighborsClassifier(n_neighbors=1)
knn.fit(X_train, y_train)
visualize_clf(knn, X_train, y_train, "kNN Model(k=1)", "PCR_01", "PCR_02")

#Q3
from sklearn.model_selection import cross_validate

k_values  = list(range(1, 20, 2)) + list(range(20, 871, 85))
validation_scores= np.empty(shape=len(k_values), dtype=float)
train_scores = np.empty(shape=len(k_values), dtype=float)

for index, k in enumerate(k_values):
  knn = KNeighborsClassifier(n_neighbors=k)
  knn.fit(X_train, y_train)
  results = cross_validate(knn, X_train, y=y_train, cv=8,  return_train_score=True)
  train_scores[index] = results["train_score"].mean()
  validation_scores[index] = results["test_score"].mean()

  
# print(train_scores)
# print(validation_scores)
plt.semilogx(k_values, train_scores, label="train")
plt.semilogx(k_values ,validation_scores, label="validation")
plt.grid(alpha=0.5)
plt.legend(('train score', 'validation score'), loc='lower left', shadow=True)
plt.suptitle(t="Q3 TITLE")
plt.xlabel("k")
plt.ylabel("score")

print("best k is:", k_values[np.argmax(validation_scores)])
print("its mean training and validation accuracies:", train_scores[np.argmax(validation_scores)], validation_scores[np.argmax(validation_scores)])

#Q4
knn = KNeighborsClassifier(n_neighbors=k_values[np.argmax(validation_scores)])
knn.fit(X_train, y_train)
visualize_clf(knn, X_train, y_train, 
              "kNN Model(k=)" + str(k_values[np.argmax(validation_scores)]), "PCR_01", "PCR_02")
X_test = test[["PCR_01", "PCR_02"]]
y_test = test.spread
print("test score: ", knn.score(X_test, y_test))

#Q5
knn1 = KNeighborsClassifier(n_neighbors=1)
knn501 = KNeighborsClassifier(n_neighbors=501)
knn1.fit(X_train, y_train)
knn501.fit(X_train, y_train)
visualize_clf(knn1, X_train, y_train, "kNN Model(k=1)", "PCR_01", "PCR_02")
visualize_clf(knn501, X_train, y_train, "kNN Model(k=501)", "PCR_01", "PCR_02")

#Q6

k_values  = list(range(1, 20, 2)) + list(range(20, 871, 85))
validation_scores= np.empty(shape=len(k_values), dtype=float)
train_scores = np.empty(shape=len(k_values), dtype=float)

X_train = train.drop(['risk', 'spread'], axis=1, inplace=False)
y_train = train.spread #TODO: Should include risk label?

for index, k in enumerate(k_values):
  knn = KNeighborsClassifier(n_neighbors=k)
  knn.fit(X_train, y_train)
  results = cross_validate(knn, X_train, y=y_train, cv=8,  return_train_score=True)
  train_scores[index] = results["train_score"].mean()
  validation_scores[index] = results["test_score"].mean()

# print(train_scores)
# print(validation_scores)
plt.semilogx(k_values, train_scores, label="train")
plt.semilogx(k_values ,validation_scores, label="validation")
plt.grid(alpha=0.5)
plt.legend(('train score', 'validation score'), loc='upper right', shadow=True)
plt.suptitle(t="Q6 TITLE")
plt.xlabel("k")
plt.ylabel("score")

print("best k is:", k_values[np.argmax(validation_scores)])
print("its mean training and validation accuracies:", train_scores[np.argmax(validation_scores)], validation_scores[np.argmax(validation_scores)])

#Q7
from sklearn.tree import DecisionTreeClassifier
from sklearn import tree
clf = DecisionTreeClassifier(criterion="entropy", max_depth=4)
clf.fit(X_train, train.risk)
plt.figure(figsize=(25,25))
_ = tree.plot_tree(clf, feature_names=X_train.columns, filled=True, fontsize=10)
print("training accuracy:", clf.score(X_train, train.risk))

#Q8
from sklearn.model_selection import GridSearchCV
# parameters = {'max_depth': range(1,20), 'min_samples_leaf': range(1,50)}
parameters = {'max_depth': range(1,20,2), 'min_samples_leaf': range(1,20,2)}
Decision_tree = DecisionTreeClassifier(criterion="entropy")
clf = GridSearchCV(Decision_tree, parameters, cv=8, return_train_score=True)
clf.fit(X_train, train.risk)
print(clf.best_estimator_)

pvt_train_mean = pd.pivot_table(pd.DataFrame(clf.cv_results_), values='mean_train_score', index='param_max_depth', columns='param_min_samples_leaf')
pvt_validation_mean = pd.pivot_table(pd.DataFrame(clf.cv_results_), values='mean_test_score', index='param_max_depth', columns='param_min_samples_leaf')

fig, axes = plt.subplots(1,2, figsize=(18, 5))
axes[0] = sns.heatmap(pvt_train_mean, vmin=0.5, vmax=1, cmap="hot", annot=True, ax=axes[0])
axes[0].set_title("mean train accuracy")
axes[0].set_xlabel("min_samples_leaf")
axes[0].set_ylabel("max_depth")

axes[1] = sns.heatmap(pvt_validation_mean, vmin=0.5, vmax=1, cmap="hot", annot=True, ax=axes[1])
axes[1].set_title("mean validation accuracy")
axes[1].set_xlabel("min_samples_leaf")
axes[1].set_ylabel("max_depth")
plt.show()
# supported values for cmap are:
# 'Accent', 'Accent_r', 'Blues', 'Blues_r', 'BrBG', 'BrBG_r', 'BuGn', 'BuGn_r', 
# 'BuPu', 'BuPu_r', 'CMRmap', 'CMRmap_r', 'Dark2', 'Dark2_r', 'GnBu', 'GnBu_r', 'Greens', 'Greens_r', 'Greys', 'Greys_r', 'OrRd', 'OrRd_r', 'Oranges', 'Oranges_r', 'PRGn', 'PRGn_r', 'Paired', 'Paired_r', 'Pastel1', 'Pastel1_r', 'Pastel2', 'Pastel2_r', 'PiYG', 'PiYG_r', 'PuBu', 'PuBuGn', 'PuBuGn_r', 'PuBu_r', 'PuOr', 'PuOr_r', 'PuRd', 'PuRd_r', 'Purples', 'Purples_r', 'RdBu', 'RdBu_r', 'RdGy', 'RdGy_r', 'RdPu', 'RdPu_r', 'RdYlBu', 'RdYlBu_r', 'RdYlGn', 'RdYlGn_r', 'Reds', 'Reds_r', 'Set1', 'Set1_r', 'Set2', 'Set2_r', 'Set3', 'Set3_r', 'Spectral', 'Spectral_r', 'Wistia', 'Wistia_r', 'YlGn', 'YlGnBu', 'YlGnBu_r', 'YlGn_r', 'YlOrBr', 'YlOrBr_r', 'YlOrRd', 'YlOrRd_r', 'afmhot', 'afmhot_r', 'autumn', 'autumn_r', 'binary', 'binary_r', 'bone', 'bone_r', 'brg', 'brg_r', 'bwr', 'bwr_r', 'cividis', 'cividis_r', 'cool', 'cool_r', 'coolwarm', 'coolwarm_r', 'copper', 'copper_r', 'crest', 'crest_r', 'cubehelix', 'cubehelix_r', 'flag', 'flag_r', 'flare', 'flare_r', 'gist_earth', 'gist_earth_r', 'gist_gray', 'gist_gray_r', 'gist_heat', 'gist_heat_r', 'gist_ncar', 'gist_ncar_r', 'gist_rainbow', 'gist_rainbow_r', 'gist_stern', 'gist_stern_r', 'gist_yarg', 'gist_yarg_r', 'gnuplot', 'gnuplot2', 'gnuplot2_r', 'gnuplot_r', 'gray', 'gray_r', 'hot', 'hot_r', 'hsv', 'hsv_r', 'icefire', 'icefire_r', 'inferno', 'inferno_r', 'jet', 'jet_r'